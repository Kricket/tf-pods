{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Démonstration 2\n",
    "\n",
    "### Utilisation d'un Réseau de Neurones Artificiel pour approximer la recherche arborescente\n",
    "\n",
    "Comme on est dans un nouveau contexte, on doit recréer les objets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pod.board import PodBoard\n",
    "from pod.player import Player\n",
    "from pod.controller import SimpleController, MediumController, CleverController\n",
    "from pod.ai.greedy_controller import GreedyController\n",
    "from pod.ai.tree_search_controller import TreeSearchController\n",
    "from pod.ai.action_discretizer import ActionDiscretizer\n",
    "from pod.drawer import Drawer, draw_board\n",
    "from pod.constants import Constants\n",
    "from vec2 import Vec2\n",
    "from pod.ai.rewards import speed_reward, dist_reward, ang_reward, check_reward, make_reward, pgr, re_dc\n",
    "from pod.ai.imitating_controller import ImitatingController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = PodBoard.grid(rows=2, cols=3, x_spacing=4000, y_spacing=5000)\n",
    "board.shuffle()\n",
    "\n",
    "draw_board(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fois, on crée 2 bots :\n",
    "* Un qui sert de \"cible\" qu'on souhaite imiter\n",
    "* Et un qui se base sur un réseau de neurones pour choisir son action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arborescent_bot = TreeSearchController(board, re_dc, 4)\n",
    "neural_bot = ImitatingController(arborescent_bot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour entraîner le réseau de neurones, on laisse jouer le bot cible. On enregistre chaque état par où le bot cible passe, ainsi que l'action qu'il a choisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracy = neural_bot.train_by_playing(\n",
    "    num_episodes = 100,\n",
    "    max_turns = 100,\n",
    "    fit_epochs = 50,\n",
    "    n_proc = 6\n",
    ")\n",
    "\n",
    "plt.plot(accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neur_drawer = Drawer(\n",
    "    board,\n",
    "    controllers = [arborescent_bot, neural_bot]\n",
    ")\n",
    "\n",
    "neur_drawer.animate(\n",
    "    max_laps = 2,\n",
    "    trail_len = 20,\n",
    "    show_vel = False,\n",
    "    highlight_checks = True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
