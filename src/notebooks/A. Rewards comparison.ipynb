{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Reward Functions\n",
    "\n",
    "This shows how the different reward functions behave (especially when crossing a checkpoint).\n",
    "\n",
    "This can be used as a tool to come up with a good reward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how the reward function changes after hitting a checkpoint.\n",
    "# The goal here is to find a reward that will encourage the agent to\n",
    "# go through the check, already pointing at the next check.\n",
    "\n",
    "from pod.ai.ai_utils import gen_pods\n",
    "from pod.constants import Constants\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from pod.board import PodBoard\n",
    "from pod.util import PodState\n",
    "from pod.controller import SimpleController\n",
    "from pod.ai.rewards import speed_reward, diff_reward, dist_reward, ang_reward, check_reward, make_reward\n",
    "from pod.drawer import Drawer\n",
    "from pod.player import Player\n",
    "from vec2 import Vec2, UNIT\n",
    "\n",
    "TURNS = 20\n",
    "\n",
    "board = PodBoard.grid(rows=1, cols=3, spacing=4000)\n",
    "\n",
    "# Generate some starting points\n",
    "pods = []\n",
    "labels = []\n",
    "for ang in np.arange(0, math.pi + 0.00001, math.pi / 4):\n",
    "    check_to_pos = UNIT.rotate(ang) * (2 * Constants.check_radius())\n",
    "    vel = UNIT.rotate(ang + math.pi) * (Constants.max_vel() * 0.1)\n",
    "    pods.append(PodState(\n",
    "        pos=board.checkpoints[0] + check_to_pos,\n",
    "        vel=vel,\n",
    "        angle=ang + math.pi\n",
    "    ))\n",
    "    labels.append(\"%.1fÂ°\" % (ang * 180/math.pi))\n",
    "\n",
    "# For each starting point, create a Player\n",
    "players = [Player(SimpleController(board), pod) for pod in pods]\n",
    "    \n",
    "drawer = Drawer(\n",
    "    board,\n",
    "    players=players,\n",
    "    labels=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the initial state of the board and players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawer.draw_frame(pods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the players playing through a few frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawer.animate(max_frames=TURNS, fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, the interesting part: compare the different reward functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_func = make_reward([\n",
    "    (0.2, speed_reward),\n",
    "    (0.2, diff_reward),\n",
    "    (0.2, dist_reward),\n",
    "    (0.02, ang_reward),\n",
    "    (0.2, check_reward)\n",
    "])\n",
    "\n",
    "player_idx = -1 # Which player to use for comparison\n",
    "drawer.compare_rewards([\n",
    "    ('custom', r_func),\n",
    "    ('speed', speed_reward),\n",
    "    ('diff', diff_reward),\n",
    "    ('dist', dist_reward),\n",
    "    ('ang', ang_reward),\n",
    "], [players[player_idx]], [labels[player_idx]], max_frames=TURNS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
