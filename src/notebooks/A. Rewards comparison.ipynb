{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Reward Functions\n",
    "\n",
    "This shows how the different reward functions behave (especially when crossing a checkpoint).\n",
    "\n",
    "This can be used as a tool to come up with a good reward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how the reward function changes after hitting a checkpoint.\n",
    "# The goal here is to find a reward that will encourage the agent to\n",
    "# go through the check, already pointing at the next check.\n",
    "\n",
    "from pod.ai.ai_utils import gen_pods\n",
    "from pod.constants import Constants\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from pod.board import PodBoard\n",
    "from pod.util import PodState\n",
    "from pod.controller import SimpleController\n",
    "from pod.ai.rewards import speed_reward, diff_reward, dist_reward, ang_reward, check_reward, make_reward, pgr, regood\n",
    "from pod.drawer import Drawer\n",
    "from pod.player import Player\n",
    "from vec2 import Vec2, UNIT\n",
    "\n",
    "TURNS = 100\n",
    "\n",
    "board = PodBoard.grid(rows=2, cols=3).reorder([3,1,0,2,4,5])\n",
    "\n",
    "# Generate some starting points\n",
    "pods = []\n",
    "labels = []\n",
    "for ang in np.arange(0, math.pi + 0.00001, math.pi / 4):\n",
    "    check_to_pos = UNIT.rotate(ang) * (2 * Constants.check_radius())\n",
    "    vel = UNIT.rotate(ang + math.pi) * (Constants.max_vel() * 0.1)\n",
    "    pods.append(PodState(\n",
    "        pos=board.checkpoints[0] + check_to_pos,\n",
    "        vel=vel,\n",
    "        angle=ang + math.pi\n",
    "    ))\n",
    "    labels.append(\"%.1fÂ°\" % (ang * 180/math.pi))\n",
    "\n",
    "# For each starting point, create a Player\n",
    "players = [Player(SimpleController(board), pod) for pod in pods]\n",
    "    \n",
    "drawer = Drawer(\n",
    "    board,\n",
    "    players=players,\n",
    "    labels=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial state of game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawer.draw_frame(pods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the players playing through a few frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawer.animate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of reward functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "drawer.compare_rewards([\n",
    "#    ('pgr', pgr),\n",
    "    ('regood', regood),\n",
    "#    ('speed', speed_reward),\n",
    "#    ('diff', diff_reward),\n",
    "#    ('dist', dist_reward),\n",
    "], [0, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a good reward\n",
    "\n",
    "Enumerate lots of combinations of the different reward functions.\n",
    "Play them to see which one works best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pod.board import PodBoard\n",
    "from pod.ai.tree_search_controller import TreeSearchController\n",
    "from pod.player import Player\n",
    "from pod.ai.rewards import speed_reward, diff_reward, dist_reward, ang_reward, check_reward, make_reward, pgr, regood\n",
    "\n",
    "TO_BEAT = 197\n",
    "MAX_TURNS = 210\n",
    "best = MAX_TURNS\n",
    "\n",
    "dist_sum = 0\n",
    "ang_sum = 0\n",
    "check_sum = 0\n",
    "n_sums = 0\n",
    "\n",
    "board = PodBoard.grid(3, 2)\n",
    "\n",
    "for x_dist in range(8,11):\n",
    "    for x_ang in range(1,4):\n",
    "        for x_check in range(2):\n",
    "            r_func = make_reward([\n",
    "                (x_dist, dist_reward),\n",
    "                (x_ang, ang_reward),\n",
    "                (x_check, check_reward)\n",
    "            ])\n",
    "            p = Player(TreeSearchController(board, r_func, 2))\n",
    "\n",
    "            while(p.pod.laps < 2 and p.pod.turns < MAX_TURNS):\n",
    "                p.step()\n",
    "\n",
    "            if p.pod.turns <= best:\n",
    "                print(\"dist {} ang {} check {} ---> {}\".format(\n",
    "                    x_dist, x_ang, x_check, p.pod.turns))\n",
    "                best = p.pod.turns\n",
    "                if p.pod.turns <= TO_BEAT:\n",
    "                    dist_sum += x_dist\n",
    "                    ang_sum += x_ang\n",
    "                    check_sum += x_check\n",
    "                    n_sums += 1\n",
    "\n",
    "print(\"Avg dist %.5f ang %.5f check %.5f\" % (dist_sum / n_sums, ang_sum / n_sums, check_sum / n_sums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pod.drawer import Drawer\n",
    "\n",
    "drawer = Drawer(board, controllers=[\n",
    "    RewardController(board, make_reward([\n",
    "        (92.29268, dist_reward),\n",
    "        (20.34146, ang_reward),\n",
    "    ])),\n",
    "    RewardController(board, make_reward([\n",
    "        (1, speed_reward),\n",
    "        (1, ang_reward),\n",
    "        (1, check_reward),\n",
    "    ])),\n",
    "], labels=['precise', 'speed'])\n",
    "\n",
    "drawer.animate(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal action discretization\n",
    "\n",
    "Here we try out different levels of precision in the discretization of the action space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pod.board import PodBoard\n",
    "from pod.ai.tree_search_controller import TreeSearchController\n",
    "from pod.ai.rewards import regood\n",
    "from pod.drawer import Drawer\n",
    "from pod.ai.action_discretizer import ActionDiscretizer\n",
    "\n",
    "board = PodBoard.grid(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2a3 = TreeSearchController(board, regood, max_depth=3, ad=ActionDiscretizer(2,3))\n",
    "t5a3 = TreeSearchController(board, regood, max_depth=3, ad=ActionDiscretizer(5,3))\n",
    "t2a9 = TreeSearchController(board, regood, max_depth=3, ad=ActionDiscretizer(2,9))\n",
    "t5a9 = TreeSearchController(board, regood, max_depth=3, ad=ActionDiscretizer(5,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawer = Drawer(\n",
    "    board,\n",
    "    controllers=[t5a9, t2a9, t5a3, t2a3],\n",
    "    labels=['t5a9', 't2a9', 't5a3', 't2a3']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawer.animate(100, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawer.chart_rewards(regood)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
