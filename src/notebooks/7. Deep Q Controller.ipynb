{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydevd_pycharm\n",
    "pydevd_pycharm.settrace('host.docker.internal', port=9999, stdoutToServer=True, stderrToServer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pod.board import PodBoard\n",
    "from pod.ai.deep_q_controller import DeepQController\n",
    "from pod.controller import SimpleController\n",
    "from pod.drawer import Drawer\n",
    "from pod.ai.rewards import re_dca\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = PodBoard.trainer()\n",
    "q_con = DeepQController(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewrite test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "q_con.board = PodBoard.trainer()\n",
    "all_rewards = []\n",
    "all_losses = []\n",
    "\n",
    "for p in range(10):\n",
    "    prob = (10 - p) / 10\n",
    "    print(\"P(random move) = {}\".format(prob))\n",
    "    rewards, losses = q_con.train_progressively(\n",
    "        dist_increment=300,\n",
    "        ep_per_dist=1000,\n",
    "        num_incr=10,\n",
    "        prob_rand_action=prob\n",
    "    )\n",
    "    avg_rew = sum(rewards) / len(rewards)\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "    print(\" ---> Average best reward: {}  Average loss: {}\".format(avg_rew, avg_loss))\n",
    "    all_rewards.append(avg_rew)\n",
    "    all_losses.append(avg_loss)\n",
    "\n",
    "plt.plot(all_rewards)\n",
    "plt.legend([\"Average reward per epoch\"])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(all_losses)\n",
    "plt.legend([\"Average loss per epoch\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online training, using exploration from random starting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rewards, accuracy = controller.train()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(rewards)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracy)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training from a predefined set of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pod.ai.ai_utils import gen_pods\n",
    "from pod.constants import Constants\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "pods_everywhere = gen_pods(\n",
    "    board.checkpoints[0],\n",
    "    np.arange(Constants.check_radius(), 10000, 1000),\n",
    "    np.arange(math.pi * -0.9, math.pi * 0.91, math.pi * 0.2),\n",
    "    np.arange(math.pi * -0.9, math.pi * 0.91, math.pi * 0.2),\n",
    "    np.arange(0, Constants.max_vel() + 1, Constants.max_vel() / 5)\n",
    ")\n",
    "\n",
    "# TODO: training goes much better if I add extra pods pointing towards the check...why?\n",
    "pods_focused = gen_pods(\n",
    "    board.checkpoints[0],\n",
    "    np.arange(Constants.check_radius(), 10000, 1000),\n",
    "    np.arange(-0.3, 0.3, 0.05),\n",
    "    np.arange(math.pi * -0.9, math.pi * 0.91, math.pi * 0.2),\n",
    "    np.arange(0, Constants.max_vel() + 1, Constants.max_vel() / 5)\n",
    ")\n",
    "\n",
    "pods = [*pods_everywhere, *pods_focused]\n",
    "\n",
    "print(\"{} total states\".format(len(pods)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracy = controller.train_from_examples(pods)\n",
    "\n",
    "plt.plot(accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "drawer = Drawer(board, controllers=[q_con, SimpleController(board)])\n",
    "drawer.players[0].pod.angle = 3.14\n",
    "drawer.animate(max_turns=40, reset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawer.chart_rewards(re_dca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "import tensorflow as tf\n",
    "\n",
    "for i in range(10):\n",
    "    v = [random() for j in range(6)]\n",
    "#    print(\"Input: {}\".format(v))\n",
    "    o = controller.model(tf.constant([v]))\n",
    "    print(\"Output: {}\".format(o))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vec2 import Vec2\n",
    "from pod.util import PodState\n",
    "import tensorflow as tf\n",
    "controller.model = tf.keras.models.load_model(\"/tmp/dq\", custom_objects = {\"LeakyReLU\": tf.keras.layers.LeakyReLU})\n",
    "\n",
    "for x in range(0, 16001, 4000):\n",
    "    for y in range(0, 9001, 3000):\n",
    "        pod = PodState(pos=Vec2(x, y))\n",
    "        print(str(controller.model(tf.constant([controller.vectorizer.to_vector(board, pod)]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
